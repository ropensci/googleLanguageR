<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Call Google Speech API — gl_speech • googleLanguageR</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>
  
  
<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">googleLanguageR</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../articles/translation.html">
    <span class="fa fa-globe fa-lg"></span>
     
    Translation API
  </a>
</li>
<li>
  <a href="../articles/nlp.html">
    <span class="fa fa-object-group fa-lg"></span>
     
    NLP API
  </a>
</li>
<li>
  <a href="../articles/speech.html">
    <span class="fa fa-comment fa-lg"></span>
     
    Speech API
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Help
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../reference/index.html">Function Reference</a>
    </li>
    <li>
      <a href="../news/index.html">News</a>
    </li>
  </ul>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://cloud.google.com/products/machine-learning/">
    <span class="fa fa-google fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/ropensci/googleLanguageR">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://docs.google.com/forms/d/e/1FAIpQLSerjirmMpB3b7LmBs_Vx_XPIE9IrhpCpPg1jUcpfBcivA3uBw/viewform">
    <span class="fa fa-slack fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Call Google Speech API</h1>
    </div>

    
    <p>Turn audio into text</p>
    

    <pre class="usage"><span class='fu'>gl_speech</span>(<span class='no'>audio_source</span>, <span class='kw'>encoding</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"LINEAR16"</span>, <span class='st'>"FLAC"</span>, <span class='st'>"MULAW"</span>, <span class='st'>"AMR"</span>,
  <span class='st'>"AMR_WB"</span>, <span class='st'>"OGG_OPUS"</span>, <span class='st'>"SPEEX_WITH_HEADER_BYTE"</span>), <span class='kw'>sampleRateHertz</span> <span class='kw'>=</span> <span class='fl'>16000L</span>,
  <span class='kw'>languageCode</span> <span class='kw'>=</span> <span class='st'>"en-US"</span>, <span class='kw'>maxAlternatives</span> <span class='kw'>=</span> <span class='fl'>1L</span>, <span class='kw'>profanityFilter</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>speechContexts</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>asynch</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a> Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>audio_source</th>
      <td><p>File location of audio data, or Google Cloud Storage URI</p></td>
    </tr>
    <tr>
      <th>encoding</th>
      <td><p>Encoding of audio data sent</p></td>
    </tr>
    <tr>
      <th>sampleRateHertz</th>
      <td><p>Sample rate in Hertz of audio data. Valid values <code>8000-48000</code>. Optimal <code>16000</code></p></td>
    </tr>
    <tr>
      <th>languageCode</th>
      <td><p>Language of the supplied audio as a <code>BCP-47</code> language tag</p></td>
    </tr>
    <tr>
      <th>maxAlternatives</th>
      <td><p>Maximum number of recognition hypotheses to be returned. <code>0-30</code></p></td>
    </tr>
    <tr>
      <th>profanityFilter</th>
      <td><p>If <code>TRUE</code> will attempt to filter out profanities</p></td>
    </tr>
    <tr>
      <th>speechContexts</th>
      <td><p>An optional character vector of context to assist the speech recognition</p></td>
    </tr>
    <tr>
      <th>asynch</th>
      <td><p>If your <code>audio_source</code> is greater than 60 seconds, set this to TRUE to return an asynchronous call</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>A tibble of three columns: <code>transcript</code>, the <code>confidence</code> with the number of rows equal to the <code>maxAlternatives</code>; a list-column of word timestamps.  If <code>asynch</code> is TRUE, then an operation you will need to pass to <a href='gl_speech_op.html'>gl_speech_op</a> to get the finished result.</p>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>Google Cloud Speech API enables developers to convert audio to text by applying powerful
neural network models in an easy to use API.
The API recognizes over 80 languages and variants, to support your global user base.
You can transcribe the text of users dictating to an application’s microphone,
enable command-and-control through voice, or transcribe audio files, among many other use cases.
Recognize audio uploaded in the request, and integrate with your audio storage on Google Cloud Storage,
by using the same technology Google uses to power its own products.</p>
    
    <h2 class="hasAnchor" id="audioencoding"><a class="anchor" href="#audioencoding"></a>AudioEncoding</h2>

    
    <p>Audio encoding of the data sent in the audio message. All encodings support only 1 channel (mono) audio.
Only FLAC and WAV include a header that describes the bytes of audio that follow the header.
The other encodings are raw audio bytes with no header.
For best results, the audio source should be captured and transmitted using a
lossless encoding (FLAC or LINEAR16).
Recognition accuracy may be reduced if lossy codecs, which include the other codecs listed in this section,
are used to capture or transmit the audio, particularly if background noise is present.</p>
<p>Read more on audio encodings here <a href='https://cloud.google.com/speech/docs/encoding'>https://cloud.google.com/speech/docs/encoding</a></p>
    
    <h2 class="hasAnchor" id="wordinfo"><a class="anchor" href="#wordinfo"></a>WordInfo</h2>

    
    <p>Use <code><a href='http://www.rdocumentation.org/packages/tidyr/topics/unnest'>tidyr::unnest()</a></code> to extract the word columns if needed.
    <code>startTime</code> - Time offset relative to the beginning of the audio, and corresponding to the start of the spoken word.
    <code>endTime</code> - Time offset relative to the beginning of the audio, and corresponding to the end of the spoken word.
    <code>word</code> - The word corresponding to this set of information.</p>
    
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <p><a href='https://cloud.google.com/speech/reference/rest/v1/speech/recognize'>https://cloud.google.com/speech/reference/rest/v1/speech/recognize</a></p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'>
</div><span class='co'># NOT RUN {</span>
<span class='no'>test_audio</span> <span class='kw'>&lt;-</span> <span class='fu'>system.file</span>(<span class='st'>"woman1_wb.wav"</span>, <span class='kw'>package</span> <span class='kw'>=</span> <span class='st'>"googleLanguageR"</span>)
<span class='no'>result</span> <span class='kw'>&lt;-</span> <span class='fu'>gl_speech</span>(<span class='no'>test_audio</span>)

<span class='no'>result2</span> <span class='kw'>&lt;-</span> <span class='fu'>gl_speech</span>(<span class='no'>test_audio</span>, <span class='kw'>maxAlternatives</span> <span class='kw'>=</span> <span class='fl'>2L</span>)

<span class='no'>result_brit</span> <span class='kw'>&lt;-</span> <span class='fu'>gl_speech</span>(<span class='no'>test_audio</span>, <span class='kw'>languageCode</span> <span class='kw'>=</span> <span class='st'>"en-GB"</span>)

<span class='co'>## extract word timestamps</span>
<span class='kw pkg'>tidyr</span><span class='kw ns'>::</span><span class='fu'><a href='http://www.rdocumentation.org/packages/tidyr/topics/unnest'>unnest</a></span>(<span class='no'>result_brit</span>)

<span class='co'>## make an asynchronous API request (mandatory for sound files over 60 seconds)</span>
<span class='no'>asynch</span> <span class='kw'>&lt;-</span> <span class='fu'>gl_speech</span>(<span class='no'>test_audio</span>, <span class='kw'>asynch</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)

<span class='co'>## Send to gl_speech_op() for status or finished result</span>
<span class='fu'><a href='gl_speech_op.html'>gl_speech_op</a></span>(<span class='no'>asynch</span>)

<span class='co'># }</span><div class='input'>

</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>

      <li><a href="#details">Details</a></li>

      <li><a href="#audioencoding">AudioEncoding</a></li>

      <li><a href="#wordinfo">WordInfo</a></li>

      <li><a href="#see-also">See also</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by <a href='http://code.markedmondson.me'>Mark Edmondson</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
